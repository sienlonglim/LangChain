{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6e49bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import time\n",
    "from openai import OpenAI\n",
    "from io import BytesIO\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the API key from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI() # The default API will call os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# This if we want to use the .env file's API key\n",
    "#import dotenv\n",
    "#client = OpenAI(api_key=dotenv.get_key(\".env\", 'OPENAI_API_KEY')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic prompting\n",
    "Available models:\n",
    "1. gpt-3.5-turbo (maximum limit 4097 tokens)\n",
    "2. dall-e-3\n",
    "3. whisper-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionUsage(completion_tokens=38, prompt_tokens=30, total_tokens=68)\n",
      "{\n",
      "  \"method\": \"GET\",\n",
      "  \"url\": \"https://api.example.com/users\",\n",
      "  \"headers\": {\n",
      "    \"Authorization\": \"Bearer <access_token>\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# JSON format\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo-1106\",\n",
    "    response_format={ \"type\": \"json_object\" },\n",
    "    seed = None, # Optional, allows more deterministic response\n",
    "    temperature = 1, # Default 1, between 0-2, higher temperatures = more random\n",
    "    messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant designed to output JSON.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write an example of a restful API call\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(response.usage)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-response streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00s : 1\n",
      "0.00s : \n",
      "\n",
      "0.00s : 2\n",
      "0.01s : \n",
      "\n",
      "0.01s : 3\n",
      "0.01s : \n",
      "\n",
      "0.01s : 4\n",
      "0.01s : \n",
      "\n",
      "0.01s : 5\n",
      "0.02s : \n",
      "\n",
      "0.02s : 6\n",
      "0.02s : \n",
      "\n",
      "0.02s : 7\n",
      "0.02s : \n",
      "\n",
      "0.02s : 8\n",
      "0.03s : \n",
      "\n",
      "0.03s : 9\n",
      "0.03s : \n",
      "\n",
      "0.03s : 10\n",
      "Full response received 0.03 seconds after request\n",
      "Full conversation received: 1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo-1106\",\n",
    "    stream = True, # event stream like ChatGPT\n",
    "    seed = None, # Optional, allows more deterministic response\n",
    "    temperature = 1, # Default 1, between 0-2, higher temperatures = more random\n",
    "    messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Count from 1 up to 10, answer line by line\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "# create variables to collect the stream of chunks\n",
    "collected_chunks = []\n",
    "collected_messages = []\n",
    "# iterate through the stream of events\n",
    "for chunk in response:\n",
    "    chunk_time = time.time() - start_time  # calculate the time delay of the chunk\n",
    "    collected_chunks.append(chunk)  # save the event response\n",
    "    chunk_message = chunk.choices[0].delta.content\n",
    "    if chunk_message:\n",
    "      collected_messages.append(chunk_message)  # save the message\n",
    "      print(f\"{chunk_time:.2f}s : {chunk_message}\")  # print the delay and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full response received 0.03 seconds after request\n",
      "Full conversation received: \n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# print the time delay and text received\n",
    "print(f\"Full response received {chunk_time:.2f} seconds after request\")\n",
    "full_reply_content = ''.join(collected_messages)\n",
    "print(f\"Full conversation received: \\n{full_reply_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionUsage(completion_tokens=97, prompt_tokens=107, total_tokens=204)\n",
      "Generate an image of a charming Maltipoo with short legs and a slender build. The Maltipoo has a frontal view, with short, curly ivory hair on its head and frizzy hair on its body. It is depicted in the living room of a stylish Singapore apartment, illuminated by abundant sunlight. The apartment boasts white parquet flooring, creating a bright and welcoming atmosphere. The adorable Maltipoo is captured smiling at its owner, exuding joy and affection.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo-1106\",\n",
    "    seed = None, # Optional, allows more deterministic response\n",
    "    temperature = 1, # Default 1, between 0-2, higher temperatures = more random\n",
    "    messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": '''Refine this prompt to be used in dall-e-3 image generation, add as many descriptive terms as possible: \n",
    "     Frontal view of a short-legged and slim maltipoo, \n",
    "    it has short curly ivory hair at its head, \n",
    "    frizzy hair on its body. It is in living room of a Singapore apartment on a sunny day, \n",
    "    the apartment has white parquet flooring, smiling at the sight of its owner'''}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(response.usage)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revised prompt: A delicately featured, short-legged, slim Maltipoo sits proudly in the living room of a high-rise apartment in Singapore, bathed in the glow of a sunny day. The petite dog bears short, curly ivory hair atop its head, giving way to a frizzier coat along its body. The apartment itself boasts white parquet flooring, reflecting the abundant sunlight. The dog seems to smile, its eyes radiating joy upon seeing its owner come into view.\n",
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-nIrXgtYCfmp1q8D9HgkO25s4/user-vbafwuDm7MpYYk4ppAR6HbwX/img-Kp6WLg5vaBUS6Y58XKfJB916.png?st=2023-11-22T09%3A40%3A36Z&se=2023-11-22T11%3A40%3A36Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-11-22T00%3A58%3A39Z&ske=2023-11-23T00%3A58%3A39Z&sks=b&skv=2021-08-06&sig=GaR/CQ%2Bi6IbHobpRY9DEm28JmC0wuf2WjYSuz1d1aCg%3D\n"
     ]
    }
   ],
   "source": [
    "original = 'I NEED to test how the tool works with extremely simple prompts. DO NOT add any detail, just use it AS-IS:'\n",
    "maltipoo_prompt = '''Frontal view of a short-legged and slim maltipoo, \n",
    "    it has short curly ivory hair at its head, \n",
    "    frizzy hair on its body. It is in living room of a Singapore apartment on a sunny day, \n",
    "    the apartment has white parquet flooring, smiling at the sight of its owner'''\n",
    "\n",
    "try:\n",
    "  response = client.images.generate(\n",
    "    model=\"dall-e-3\",\n",
    "    prompt=maltipoo_prompt,\n",
    "    size=\"1024x1024\",\n",
    "    quality=\"standard\", #standard or hd\n",
    "    style = 'vivid', #vivid or natural\n",
    "    n=1\n",
    "  )\n",
    "\n",
    "  print(f\"Revised prompt: {response.data[0].revised_prompt}\")\n",
    "  image_url = response.data[0].url\n",
    "  print(image_url)\n",
    "\n",
    "except openai.OpenAIError as e:\n",
    "  print(e.http_status)\n",
    "  print(e.error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking\n",
    "Provide:\n",
    "1. image (original image)\n",
    "2. mask (transparent areas as where editing to be done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.images.edit((\n",
    "  model=\"dall-e-2\",\n",
    "  image=open(\"ignore/sunlit_lounge.png\", \"rb\"),\n",
    "  mask=open(\"ignore/mask.png\", \"rb\"),\n",
    "  prompt=\"A sunlit indoor lounge area with a pool containing a flamingo\",\n",
    "  n=1,\n",
    "  size=\"1024x1024\"\n",
    ")\n",
    "image_url = response.data[0].url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image file from disk and resize it\n",
    "filepath = 'ignore/images/futuristiclink.png'\n",
    "image = Image.open(filepath)\n",
    "width, height = 256, 256\n",
    "image = image.resize((width, height))\n",
    "\n",
    "# Convert the image to a BytesIO object\n",
    "byte_stream = BytesIO()\n",
    "image.save(byte_stream, format='PNG')\n",
    "byte_array = byte_stream.getvalue()\n",
    "\n",
    "response = client.images.create_variation(\n",
    "  image=byte_array,\n",
    "  n=1,\n",
    "  size=\"1024x1024\"\n",
    ")\n",
    "\n",
    "for i in response.data:\n",
    "    print(i.url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
